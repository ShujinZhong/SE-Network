{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1562 steps, validate for 100 steps\n",
      "Epoch 1/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 2.1827 - accuracy: 0.3347lr: 0.001\n",
      "1562/1562 [==============================] - 89s 57ms/step - loss: 2.1822 - accuracy: 0.3346 - val_loss: 1.6666 - val_accuracy: 0.4128\n",
      "Epoch 2/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 1.6501 - accuracy: 0.4414lr: 0.001\n",
      "1562/1562 [==============================] - 77s 49ms/step - loss: 1.6502 - accuracy: 0.4414 - val_loss: 1.7964 - val_accuracy: 0.3859\n",
      "Epoch 3/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 1.4731 - accuracy: 0.4968lr: 0.001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 1.4730 - accuracy: 0.4969 - val_loss: 1.5954 - val_accuracy: 0.4831\n",
      "Epoch 4/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 1.3344 - accuracy: 0.5410lr: 0.001\n",
      "1562/1562 [==============================] - 75s 48ms/step - loss: 1.3343 - accuracy: 0.5410 - val_loss: 1.5281 - val_accuracy: 0.4919\n",
      "Epoch 5/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 1.2527 - accuracy: 0.5697lr: 0.001\n",
      "1562/1562 [==============================] - 77s 49ms/step - loss: 1.2529 - accuracy: 0.5696 - val_loss: 1.7227 - val_accuracy: 0.4619\n",
      "Epoch 6/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 1.1795 - accuracy: 0.5932lr: 0.001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 1.1796 - accuracy: 0.5933 - val_loss: 1.4209 - val_accuracy: 0.5297\n",
      "Epoch 7/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 1.1162 - accuracy: 0.6167lr: 0.001\n",
      "1562/1562 [==============================] - 75s 48ms/step - loss: 1.1162 - accuracy: 0.6167 - val_loss: 1.5305 - val_accuracy: 0.5334\n",
      "Epoch 8/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 1.0553 - accuracy: 0.6335lr: 0.001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 1.0552 - accuracy: 0.6335 - val_loss: 1.4824 - val_accuracy: 0.5275\n",
      "Epoch 9/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 1.0158 - accuracy: 0.6482lr: 0.001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 1.0156 - accuracy: 0.6482 - val_loss: 1.0442 - val_accuracy: 0.6459\n",
      "Epoch 10/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.9651 - accuracy: 0.6661lr: 0.001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.9649 - accuracy: 0.6661 - val_loss: 1.2917 - val_accuracy: 0.5619\n",
      "Epoch 11/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.9362 - accuracy: 0.6746lr: 0.001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.9362 - accuracy: 0.6746 - val_loss: 1.0124 - val_accuracy: 0.6572\n",
      "Epoch 12/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.8938 - accuracy: 0.6883lr: 0.001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.8939 - accuracy: 0.6883 - val_loss: 1.6299 - val_accuracy: 0.5297\n",
      "Epoch 13/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.8640 - accuracy: 0.7008lr: 0.001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.8638 - accuracy: 0.7009 - val_loss: 1.3467 - val_accuracy: 0.5663\n",
      "Epoch 14/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.8334 - accuracy: 0.7100lr: 0.001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.8335 - accuracy: 0.7100 - val_loss: 1.1581 - val_accuracy: 0.6212\n",
      "Epoch 15/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.8124 - accuracy: 0.7190lr: 0.001\n",
      "1562/1562 [==============================] - 75s 48ms/step - loss: 0.8125 - accuracy: 0.7190 - val_loss: 1.2932 - val_accuracy: 0.6175\n",
      "Epoch 16/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.7743 - accuracy: 0.7275lr: 0.001\n",
      "1562/1562 [==============================] - 77s 49ms/step - loss: 0.7742 - accuracy: 0.7276 - val_loss: 1.0135 - val_accuracy: 0.6647\n",
      "Epoch 17/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.7595 - accuracy: 0.7371lr: 0.001\n",
      "1562/1562 [==============================] - 77s 49ms/step - loss: 0.7593 - accuracy: 0.7371 - val_loss: 0.9428 - val_accuracy: 0.6794\n",
      "Epoch 18/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.7285 - accuracy: 0.7441lr: 0.001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.7284 - accuracy: 0.7442 - val_loss: 0.9820 - val_accuracy: 0.6703\n",
      "Epoch 19/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.7204 - accuracy: 0.7504lr: 0.001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.7207 - accuracy: 0.7502 - val_loss: 0.9919 - val_accuracy: 0.6762\n",
      "Epoch 20/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.6904 - accuracy: 0.7604lr: 0.001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.6904 - accuracy: 0.7603 - val_loss: 1.1717 - val_accuracy: 0.6338\n",
      "Epoch 21/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.6676 - accuracy: 0.7657lr: 0.001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.6676 - accuracy: 0.7657 - val_loss: 0.8987 - val_accuracy: 0.6900\n",
      "Epoch 22/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.6553 - accuracy: 0.7683lr: 0.001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.6555 - accuracy: 0.7683 - val_loss: 0.9456 - val_accuracy: 0.6913\n",
      "Epoch 23/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.6231 - accuracy: 0.7815lr: 0.001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.6232 - accuracy: 0.7815 - val_loss: 1.1019 - val_accuracy: 0.6734\n",
      "Epoch 24/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.6114 - accuracy: 0.7857lr: 0.001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.6112 - accuracy: 0.7858 - val_loss: 1.0033 - val_accuracy: 0.6831\n",
      "Epoch 25/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.5991 - accuracy: 0.7891lr: 0.001\n",
      "1562/1562 [==============================] - 76s 48ms/step - loss: 0.5990 - accuracy: 0.7891 - val_loss: 0.9861 - val_accuracy: 0.6956\n",
      "Epoch 26/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.5861 - accuracy: 0.7944lr: 0.001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.5859 - accuracy: 0.7945 - val_loss: 1.0751 - val_accuracy: 0.6541\n",
      "Epoch 27/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.5687 - accuracy: 0.8012lr: 0.001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.5687 - accuracy: 0.8013 - val_loss: 1.1051 - val_accuracy: 0.6684\n",
      "Epoch 28/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.5511 - accuracy: 0.8074lr: 0.001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.5512 - accuracy: 0.8074 - val_loss: 0.9748 - val_accuracy: 0.6959\n",
      "Epoch 29/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.5307 - accuracy: 0.8139lr: 0.001\n",
      "1562/1562 [==============================] - 76s 48ms/step - loss: 0.5306 - accuracy: 0.8139 - val_loss: 1.0269 - val_accuracy: 0.6800\n",
      "Epoch 30/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.5295 - accuracy: 0.8139lr: 0.0001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.5296 - accuracy: 0.8139 - val_loss: 0.8705 - val_accuracy: 0.7166\n",
      "Epoch 31/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.4153 - accuracy: 0.8539lr: 0.0001\n",
      "1562/1562 [==============================] - 76s 48ms/step - loss: 0.4152 - accuracy: 0.8540 - val_loss: 0.7895 - val_accuracy: 0.7409\n",
      "Epoch 32/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8661lr: 0.0001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.3830 - accuracy: 0.8661 - val_loss: 0.7733 - val_accuracy: 0.7525\n",
      "Epoch 33/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.3669 - accuracy: 0.8706lr: 0.0001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.3668 - accuracy: 0.8707 - val_loss: 0.7548 - val_accuracy: 0.7516\n",
      "Epoch 34/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.3589 - accuracy: 0.8746lr: 0.0001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.3590 - accuracy: 0.8746 - val_loss: 0.8034 - val_accuracy: 0.7491\n",
      "Epoch 35/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.3528 - accuracy: 0.8767lr: 0.0001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.3528 - accuracy: 0.8767 - val_loss: 0.7791 - val_accuracy: 0.7466\n",
      "Epoch 36/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.3460 - accuracy: 0.8795lr: 0.0001\n",
      "1562/1562 [==============================] - 76s 48ms/step - loss: 0.3459 - accuracy: 0.8796 - val_loss: 0.7770 - val_accuracy: 0.7456\n",
      "Epoch 37/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.3378 - accuracy: 0.8823lr: 0.0001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.3381 - accuracy: 0.8821 - val_loss: 0.8003 - val_accuracy: 0.7491\n",
      "Epoch 38/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.3342 - accuracy: 0.8825lr: 0.0001\n",
      "1562/1562 [==============================] - 77s 49ms/step - loss: 0.3342 - accuracy: 0.8825 - val_loss: 0.7658 - val_accuracy: 0.7634\n",
      "Epoch 39/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.3265 - accuracy: 0.8867lr: 0.0001\n",
      "1562/1562 [==============================] - 76s 48ms/step - loss: 0.3265 - accuracy: 0.8866 - val_loss: 0.7824 - val_accuracy: 0.7600\n",
      "Epoch 40/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.3222 - accuracy: 0.8882lr: 0.0001\n",
      "1562/1562 [==============================] - 76s 48ms/step - loss: 0.3222 - accuracy: 0.8882 - val_loss: 0.7754 - val_accuracy: 0.7575\n",
      "Epoch 41/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.3192 - accuracy: 0.8886lr: 0.0001\n",
      "1562/1562 [==============================] - 75s 48ms/step - loss: 0.3191 - accuracy: 0.8886 - val_loss: 0.8180 - val_accuracy: 0.7381\n",
      "Epoch 42/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.3159 - accuracy: 0.8902lr: 0.0001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.3160 - accuracy: 0.8902 - val_loss: 0.7769 - val_accuracy: 0.7538\n",
      "Epoch 43/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.3078 - accuracy: 0.8931lr: 0.0001\n",
      "1562/1562 [==============================] - 76s 48ms/step - loss: 0.3080 - accuracy: 0.8931 - val_loss: 0.8043 - val_accuracy: 0.7506\n",
      "Epoch 44/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.3084 - accuracy: 0.8934lr: 0.0001\n",
      "1562/1562 [==============================] - 75s 48ms/step - loss: 0.3086 - accuracy: 0.8933 - val_loss: 0.7950 - val_accuracy: 0.7478\n",
      "Epoch 45/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.3044 - accuracy: 0.8938lr: 0.0001\n",
      "1562/1562 [==============================] - 75s 48ms/step - loss: 0.3044 - accuracy: 0.8938 - val_loss: 0.7690 - val_accuracy: 0.7541\n",
      "Epoch 46/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.3013 - accuracy: 0.8955lr: 0.0001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.3013 - accuracy: 0.8955 - val_loss: 0.8085 - val_accuracy: 0.7459\n",
      "Epoch 47/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2941 - accuracy: 0.8970lr: 0.0001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.2940 - accuracy: 0.8970 - val_loss: 0.8017 - val_accuracy: 0.7541\n",
      "Epoch 48/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2983 - accuracy: 0.8974lr: 0.0001\n",
      "1562/1562 [==============================] - 76s 48ms/step - loss: 0.2983 - accuracy: 0.8974 - val_loss: 0.7619 - val_accuracy: 0.7653\n",
      "Epoch 49/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2872 - accuracy: 0.9004lr: 0.0001\n",
      "1562/1562 [==============================] - 76s 48ms/step - loss: 0.2872 - accuracy: 0.9003 - val_loss: 0.7747 - val_accuracy: 0.7631\n",
      "Epoch 50/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2821 - accuracy: 0.9026lr: 0.0001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.2821 - accuracy: 0.9026 - val_loss: 0.7964 - val_accuracy: 0.7500\n",
      "Epoch 51/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2813 - accuracy: 0.9007lr: 0.0001\n",
      "1562/1562 [==============================] - 76s 48ms/step - loss: 0.2813 - accuracy: 0.9007 - val_loss: 0.8263 - val_accuracy: 0.7509\n",
      "Epoch 52/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2766 - accuracy: 0.9042lr: 0.0001\n",
      "1562/1562 [==============================] - 76s 48ms/step - loss: 0.2765 - accuracy: 0.9042 - val_loss: 0.8021 - val_accuracy: 0.7588\n",
      "Epoch 53/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2712 - accuracy: 0.9067lr: 0.0001\n",
      "1562/1562 [==============================] - 76s 48ms/step - loss: 0.2712 - accuracy: 0.9066 - val_loss: 0.7868 - val_accuracy: 0.7559\n",
      "Epoch 54/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2730 - accuracy: 0.9047lr: 0.0001\n",
      "1562/1562 [==============================] - 76s 48ms/step - loss: 0.2729 - accuracy: 0.9047 - val_loss: 0.7929 - val_accuracy: 0.7606\n",
      "Epoch 55/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2721 - accuracy: 0.9051lr: 0.0001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.2720 - accuracy: 0.9051 - val_loss: 0.7943 - val_accuracy: 0.7547\n",
      "Epoch 56/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2658 - accuracy: 0.9086lr: 0.0001\n",
      "1562/1562 [==============================] - 76s 48ms/step - loss: 0.2657 - accuracy: 0.9087 - val_loss: 0.8070 - val_accuracy: 0.7659\n",
      "Epoch 57/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2616 - accuracy: 0.9097lr: 0.0001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.2614 - accuracy: 0.9098 - val_loss: 0.8155 - val_accuracy: 0.7603\n",
      "Epoch 58/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2617 - accuracy: 0.9087lr: 0.0001\n",
      "1562/1562 [==============================] - 76s 48ms/step - loss: 0.2617 - accuracy: 0.9087 - val_loss: 0.8267 - val_accuracy: 0.7538\n",
      "Epoch 59/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2584 - accuracy: 0.9102lr: 0.0001\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.2583 - accuracy: 0.9102 - val_loss: 0.7943 - val_accuracy: 0.7625\n",
      "Epoch 60/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2544 - accuracy: 0.9123lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 77s 49ms/step - loss: 0.2543 - accuracy: 0.9123 - val_loss: 0.7804 - val_accuracy: 0.7597\n",
      "Epoch 61/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2463 - accuracy: 0.9139lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.2463 - accuracy: 0.9139 - val_loss: 0.8072 - val_accuracy: 0.7538\n",
      "Epoch 62/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2442 - accuracy: 0.9165lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.2441 - accuracy: 0.9165 - val_loss: 0.7821 - val_accuracy: 0.7591\n",
      "Epoch 63/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2423 - accuracy: 0.9159lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 76s 48ms/step - loss: 0.2423 - accuracy: 0.9159 - val_loss: 0.7854 - val_accuracy: 0.7659\n",
      "Epoch 64/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2419 - accuracy: 0.9169lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.2422 - accuracy: 0.9168 - val_loss: 0.7994 - val_accuracy: 0.7644\n",
      "Epoch 65/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2399 - accuracy: 0.9181lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 76s 48ms/step - loss: 0.2398 - accuracy: 0.9181 - val_loss: 0.8209 - val_accuracy: 0.7575\n",
      "Epoch 66/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2344 - accuracy: 0.9198lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 76s 48ms/step - loss: 0.2344 - accuracy: 0.9198 - val_loss: 0.8051 - val_accuracy: 0.7578\n",
      "Epoch 67/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2387 - accuracy: 0.9180lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.2387 - accuracy: 0.9180 - val_loss: 0.8139 - val_accuracy: 0.7569\n",
      "Epoch 68/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2413 - accuracy: 0.9162lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.2414 - accuracy: 0.9162 - val_loss: 0.8090 - val_accuracy: 0.7556\n",
      "Epoch 69/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2354 - accuracy: 0.9185lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 75s 48ms/step - loss: 0.2355 - accuracy: 0.9185 - val_loss: 0.7837 - val_accuracy: 0.7638\n",
      "Epoch 70/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2400 - accuracy: 0.9160lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 75s 48ms/step - loss: 0.2399 - accuracy: 0.9161 - val_loss: 0.8020 - val_accuracy: 0.7634\n",
      "Epoch 71/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2367 - accuracy: 0.9187lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 75s 48ms/step - loss: 0.2366 - accuracy: 0.9188 - val_loss: 0.7915 - val_accuracy: 0.7675\n",
      "Epoch 72/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2390 - accuracy: 0.9171lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.2390 - accuracy: 0.9171 - val_loss: 0.7983 - val_accuracy: 0.7609\n",
      "Epoch 73/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2384 - accuracy: 0.9164lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.2385 - accuracy: 0.9164 - val_loss: 0.7963 - val_accuracy: 0.7606\n",
      "Epoch 74/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2369 - accuracy: 0.9182lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 75s 48ms/step - loss: 0.2371 - accuracy: 0.9182 - val_loss: 0.8063 - val_accuracy: 0.7675\n",
      "Epoch 75/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2410 - accuracy: 0.9171lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.2409 - accuracy: 0.9171 - val_loss: 0.8022 - val_accuracy: 0.7644\n",
      "Epoch 76/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2344 - accuracy: 0.9186lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.2345 - accuracy: 0.9186 - val_loss: 0.8041 - val_accuracy: 0.7572\n",
      "Epoch 77/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2373 - accuracy: 0.9188lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 76s 48ms/step - loss: 0.2372 - accuracy: 0.9189 - val_loss: 0.8238 - val_accuracy: 0.7584\n",
      "Epoch 78/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2355 - accuracy: 0.9190lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.2355 - accuracy: 0.9190 - val_loss: 0.7790 - val_accuracy: 0.7703\n",
      "Epoch 79/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2334 - accuracy: 0.9200lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.2333 - accuracy: 0.9200 - val_loss: 0.8001 - val_accuracy: 0.7622\n",
      "Epoch 80/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2358 - accuracy: 0.9188lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.2359 - accuracy: 0.9188 - val_loss: 0.7863 - val_accuracy: 0.7575\n",
      "Epoch 81/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2354 - accuracy: 0.9186lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.2354 - accuracy: 0.9185 - val_loss: 0.7982 - val_accuracy: 0.7616\n",
      "Epoch 82/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2354 - accuracy: 0.9177lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 75s 48ms/step - loss: 0.2355 - accuracy: 0.9177 - val_loss: 0.8002 - val_accuracy: 0.7559\n",
      "Epoch 83/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2335 - accuracy: 0.9192lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.2335 - accuracy: 0.9192 - val_loss: 0.8341 - val_accuracy: 0.7556\n",
      "Epoch 84/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2341 - accuracy: 0.9190lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.2340 - accuracy: 0.9190 - val_loss: 0.8323 - val_accuracy: 0.7550\n",
      "Epoch 85/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2321 - accuracy: 0.9191lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.2321 - accuracy: 0.9191 - val_loss: 0.8055 - val_accuracy: 0.7697\n",
      "Epoch 86/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2340 - accuracy: 0.9204lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 76s 48ms/step - loss: 0.2340 - accuracy: 0.9204 - val_loss: 0.8268 - val_accuracy: 0.7525\n",
      "Epoch 87/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2280 - accuracy: 0.9217lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 76s 48ms/step - loss: 0.2280 - accuracy: 0.9217 - val_loss: 0.8289 - val_accuracy: 0.7516\n",
      "Epoch 88/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2314 - accuracy: 0.9205lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 77s 49ms/step - loss: 0.2314 - accuracy: 0.9206 - val_loss: 0.7929 - val_accuracy: 0.7688\n",
      "Epoch 89/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2325 - accuracy: 0.9193lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.2325 - accuracy: 0.9193 - val_loss: 0.7988 - val_accuracy: 0.7597\n",
      "Epoch 90/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2307 - accuracy: 0.9188lr: 1.0000000000000002e-06\n",
      "1562/1562 [==============================] - 76s 48ms/step - loss: 0.2310 - accuracy: 0.9187 - val_loss: 0.7968 - val_accuracy: 0.7706\n",
      "Epoch 91/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2283 - accuracy: 0.9213lr: 1.0000000000000002e-06\n",
      "1562/1562 [==============================] - 77s 49ms/step - loss: 0.2282 - accuracy: 0.9213 - val_loss: 0.7751 - val_accuracy: 0.7663\n",
      "Epoch 92/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2314 - accuracy: 0.9204lr: 1.0000000000000002e-06\n",
      "1562/1562 [==============================] - 77s 49ms/step - loss: 0.2316 - accuracy: 0.9203 - val_loss: 0.7593 - val_accuracy: 0.7703\n",
      "Epoch 93/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2318 - accuracy: 0.9202lr: 1.0000000000000002e-06\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.2317 - accuracy: 0.9202 - val_loss: 0.7852 - val_accuracy: 0.7547\n",
      "Epoch 94/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2340 - accuracy: 0.9192lr: 1.0000000000000002e-06\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.2341 - accuracy: 0.9192 - val_loss: 0.8082 - val_accuracy: 0.7547\n",
      "Epoch 95/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2328 - accuracy: 0.9194lr: 1.0000000000000002e-06\n",
      "1562/1562 [==============================] - 77s 49ms/step - loss: 0.2328 - accuracy: 0.9194 - val_loss: 0.7918 - val_accuracy: 0.7644\n",
      "Epoch 96/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2285 - accuracy: 0.9219lr: 1.0000000000000002e-06\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.2285 - accuracy: 0.9219 - val_loss: 0.7960 - val_accuracy: 0.7603\n",
      "Epoch 97/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2313 - accuracy: 0.9185lr: 1.0000000000000002e-06\n",
      "1562/1562 [==============================] - 76s 49ms/step - loss: 0.2313 - accuracy: 0.9185 - val_loss: 0.7746 - val_accuracy: 0.7641\n",
      "Epoch 98/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2278 - accuracy: 0.9219lr: 1.0000000000000002e-06\n",
      "1562/1562 [==============================] - 76s 48ms/step - loss: 0.2277 - accuracy: 0.9220 - val_loss: 0.8205 - val_accuracy: 0.7613\n",
      "Epoch 99/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2281 - accuracy: 0.9222lr: 1.0000000000000002e-06\n",
      "1562/1562 [==============================] - 77s 49ms/step - loss: 0.2281 - accuracy: 0.9222 - val_loss: 0.8051 - val_accuracy: 0.7578\n",
      "Epoch 100/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2295 - accuracy: 0.9209lr: 1.0000000000000002e-06\n",
      "1562/1562 [==============================] - 77s 49ms/step - loss: 0.2295 - accuracy: 0.9209 - val_loss: 0.8008 - val_accuracy: 0.7613\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "dataset = 'cifar10'\n",
    "train_size = 50000\n",
    "image_size = 32\n",
    "batch_size = 32\n",
    "reduction_ratio = 16\n",
    "num_classes = 10\n",
    "momentum = 0.8\n",
    "initial_learning_rate = 0.001\n",
    "drop_rate = 0.1\n",
    "epochs_per_drop = 30.0\n",
    "steps_per_epoch = train_size // batch_size\n",
    "epochs = 100\n",
    "\n",
    "ds_train = tfds.load(dataset, split='train')\n",
    "ds_test = tfds.load(dataset, split='test')\n",
    "\n",
    "def normalize_image(ele):\n",
    "    image = ele['image']\n",
    "    label = ele['label']\n",
    "    paddings = tf.constant([[4,4], [4,4], [0,0]])\n",
    "  \n",
    "    image = tf.pad(image, paddings, 'CONSTANT')\n",
    "    image = tf.image.random_crop(image, size = [32,32,3])\n",
    "    \n",
    "    image = (image - tf.reduce_min(image))/(tf.reduce_max(image)-tf.reduce_min(image))\n",
    "    return image, label\n",
    "\n",
    "ds_train = ds_train.map(normalize_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).repeat().shuffle(100).batch(batch_size).prefetch(1)\n",
    "ds_test = ds_test.map(normalize_image,  num_parallel_calls=tf.data.experimental.AUTOTUNE).repeat().shuffle(100).batch(batch_size).prefetch(1)\n",
    "\n",
    "def conv2D(x, filters, kernel=(3,3), strides=(1,1), activation=tf.nn.relu, use_bias=False):\n",
    "    x = tf.keras.layers.Conv2D(filters, kernel_size=kernel, strides=strides, use_bias=use_bias, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    if activation is not None:\n",
    "        x = tf.keras.layers.Activation(activation)(x)\n",
    "    return x\n",
    "\n",
    "def SE_layer(x, ratio=reduction_ratio):\n",
    "    depth = list(x.get_shape())[-1]\n",
    "    prev = x\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(depth//ratio, activation=tf.nn.relu)(x)\n",
    "    x = tf.keras.layers.Dense(depth, activation=tf.nn.sigmoid)(x)\n",
    "    x = tf.reshape(x, [-1, 1, 1, depth])\n",
    "    x = prev * x\n",
    "    return x\n",
    "\n",
    "def block(x, trips=[64, 64, 256], first=False, SE=False):\n",
    "    if first:\n",
    "        x = conv2D(x, trips[0], kernel=(1,1), strides=(2,2))\n",
    "    else:\n",
    "        x = conv2D(x, trips[0], kernel=(1,1))\n",
    "    x = conv2D(x, trips[1], kernel=(3,3))\n",
    "    x = conv2D(x, trips[2], kernel=(1,1))\n",
    "    if SE:\n",
    "        x = SE_layer(x)\n",
    "    return x\n",
    "\n",
    "def meta_block(x, trips=[64, 64, 256], repeats=3, downsample=True, SE=False):\n",
    "    prev = x\n",
    "    for r in range(repeats):\n",
    "        if r == 0 and downsample:\n",
    "            prev = conv2D(prev, trips[2], kernel=(1,1), strides=(2,2), activation=None)\n",
    "            x = block(x, trips=trips, first=True, SE=SE)\n",
    "            x = tf.keras.layers.Add()([x, prev])\n",
    "        elif r==0 and not downsample:\n",
    "            prev = conv2D(prev, trips[2], kernel=(1,1), activation=None)\n",
    "            x = block(x, trips=trips, SE=SE)\n",
    "            x = tf.keras.layers.Add()([x, prev])\n",
    "        else:\n",
    "            prev = x\n",
    "            x = block(x, trips=trips, SE=SE)\n",
    "            x = tf.keras.layers.Add()([x, prev])\n",
    "    return x\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(image_size, image_size, 3))\n",
    "x = conv2D(inputs, 64, kernel=(7,7), strides=(2,2))\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=2, padding='same')(x)                         \n",
    "\n",
    "### Block 1\n",
    "x = meta_block(x, trips=[64, 64, 256], repeats=3, downsample=False, SE=True)\n",
    "\n",
    "### Block 2\n",
    "x = meta_block(x, trips=[128, 128, 512], repeats=4, SE=True)\n",
    "\n",
    "### Block 3\n",
    "x = meta_block(x, trips=[256, 256, 1024], repeats=6, SE=True)\n",
    "\n",
    "### Block 4\n",
    "x = meta_block(x, trips=[512, 512, 2048], repeats=3)\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(num_classes, activation='softmax')(x) #logits \n",
    "\n",
    "SE_resnet = tf.keras.Model(inputs, x)\n",
    "\n",
    "sgd = tf.keras.optimizers.SGD(lr=0.0, momentum=momentum, decay=0.0, nesterov=False) \n",
    "\n",
    "SE_resnet.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "class LossHistory(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.lr = []\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.lr.append(step_decay(len(self.losses)))\n",
    "        print('lr:', step_decay(len(self.losses)))\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = initial_learning_rate\n",
    "    drop = drop_rate\n",
    "    epochs_drop = epochs_per_drop\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "# learning schedule callback\n",
    "loss_history = LossHistory()\n",
    "lrate = tf.keras.callbacks.LearningRateScheduler(step_decay)\n",
    "callbacks_list = [loss_history, lrate]\n",
    "\n",
    "# fit the model\n",
    "history = SE_resnet.fit(ds_train, steps_per_epoch=steps_per_epoch, validation_data=ds_test, epochs=epochs, callbacks=callbacks_list, validation_steps=100)\n",
    "\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "np.savetxt(\"SE_resnet_cifar10_accuracy.csv\", accuracy, delimiter=\",\")\n",
    "np.savetxt(\"SE_resnet_cifar10_val_accuracy.csv\", val_accuracy, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
