{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1562 steps, validate for 100 steps\n",
      "Epoch 1/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 2.1901 - accuracy: 0.3453lr: 0.001\n",
      "1562/1562 [==============================] - 72s 46ms/step - loss: 2.1905 - accuracy: 0.3452 - val_loss: 1.7079 - val_accuracy: 0.3925\n",
      "Epoch 2/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 1.7430 - accuracy: 0.4432lr: 0.001\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 1.7432 - accuracy: 0.4431 - val_loss: 1.4988 - val_accuracy: 0.4681\n",
      "Epoch 3/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 1.5972 - accuracy: 0.4892lr: 0.001\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 1.5978 - accuracy: 0.4892 - val_loss: 1.7089 - val_accuracy: 0.4972\n",
      "Epoch 4/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 1.4701 - accuracy: 0.5196lr: 0.001\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 1.4699 - accuracy: 0.5195 - val_loss: 1.4479 - val_accuracy: 0.4997\n",
      "Epoch 5/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 1.3722 - accuracy: 0.5500lr: 0.001\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 1.3719 - accuracy: 0.5500 - val_loss: 1.2740 - val_accuracy: 0.5669\n",
      "Epoch 6/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 1.2816 - accuracy: 0.5771lr: 0.001\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 1.2817 - accuracy: 0.5770 - val_loss: 1.3026 - val_accuracy: 0.5600\n",
      "Epoch 7/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 1.1954 - accuracy: 0.6014lr: 0.001\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 1.1952 - accuracy: 0.6014 - val_loss: 1.2090 - val_accuracy: 0.5825\n",
      "Epoch 8/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 1.1434 - accuracy: 0.6159lr: 0.001\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 1.1436 - accuracy: 0.6158 - val_loss: 1.2623 - val_accuracy: 0.5691\n",
      "Epoch 9/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 1.0740 - accuracy: 0.6370lr: 0.001\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 1.0739 - accuracy: 0.6370 - val_loss: 1.1997 - val_accuracy: 0.5869\n",
      "Epoch 10/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 1.0326 - accuracy: 0.6490lr: 0.001\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 1.0328 - accuracy: 0.6489 - val_loss: 1.2061 - val_accuracy: 0.5903\n",
      "Epoch 11/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 1.0167 - accuracy: 0.6571lr: 0.001\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 1.0167 - accuracy: 0.6572 - val_loss: 1.4823 - val_accuracy: 0.5391\n",
      "Epoch 12/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.9723 - accuracy: 0.6697lr: 0.001\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.9723 - accuracy: 0.6698 - val_loss: 1.5133 - val_accuracy: 0.6084\n",
      "Epoch 13/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.9318 - accuracy: 0.6849lr: 0.001\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.9318 - accuracy: 0.6849 - val_loss: 1.7233 - val_accuracy: 0.5178\n",
      "Epoch 14/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.8843 - accuracy: 0.6973lr: 0.001\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.8844 - accuracy: 0.6973 - val_loss: 2.4350 - val_accuracy: 0.4159\n",
      "Epoch 15/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.9047 - accuracy: 0.6908lr: 0.001\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.9046 - accuracy: 0.6907 - val_loss: 0.9953 - val_accuracy: 0.6631\n",
      "Epoch 16/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.8538 - accuracy: 0.7082lr: 0.001\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.8539 - accuracy: 0.7081 - val_loss: 0.9525 - val_accuracy: 0.6669\n",
      "Epoch 17/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.8158 - accuracy: 0.7207lr: 0.001\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.8155 - accuracy: 0.7208 - val_loss: 0.9913 - val_accuracy: 0.6491\n",
      "Epoch 18/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.8060 - accuracy: 0.7258lr: 0.001\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.8059 - accuracy: 0.7258 - val_loss: 2.1450 - val_accuracy: 0.5838\n",
      "Epoch 19/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.7608 - accuracy: 0.7375lr: 0.001\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.7608 - accuracy: 0.7375 - val_loss: 1.0360 - val_accuracy: 0.6819\n",
      "Epoch 20/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.7360 - accuracy: 0.7441lr: 0.001\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.7360 - accuracy: 0.7441 - val_loss: 1.1162 - val_accuracy: 0.6591\n",
      "Epoch 21/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.7238 - accuracy: 0.7513lr: 0.001\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.7236 - accuracy: 0.7514 - val_loss: 0.9527 - val_accuracy: 0.6875\n",
      "Epoch 22/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.6888 - accuracy: 0.7615lr: 0.001\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.6886 - accuracy: 0.7616 - val_loss: 0.9190 - val_accuracy: 0.6906\n",
      "Epoch 23/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.6684 - accuracy: 0.7668lr: 0.001\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.6683 - accuracy: 0.7668 - val_loss: 0.9824 - val_accuracy: 0.6725\n",
      "Epoch 24/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.6518 - accuracy: 0.7772lr: 0.001\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.6519 - accuracy: 0.7771 - val_loss: 0.9135 - val_accuracy: 0.6891\n",
      "Epoch 25/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.6347 - accuracy: 0.7821lr: 0.001\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.6348 - accuracy: 0.7821 - val_loss: 0.9356 - val_accuracy: 0.6809\n",
      "Epoch 26/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.6092 - accuracy: 0.7862lr: 0.001\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.6091 - accuracy: 0.7863 - val_loss: 1.3296 - val_accuracy: 0.6834\n",
      "Epoch 27/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.6051 - accuracy: 0.7916lr: 0.001\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.6051 - accuracy: 0.7916 - val_loss: 0.9275 - val_accuracy: 0.6859\n",
      "Epoch 28/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.5867 - accuracy: 0.7967lr: 0.001\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.5869 - accuracy: 0.7967 - val_loss: 0.8931 - val_accuracy: 0.7028\n",
      "Epoch 29/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.5750 - accuracy: 0.8009lr: 0.001\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.5750 - accuracy: 0.8008 - val_loss: 0.8950 - val_accuracy: 0.7100\n",
      "Epoch 30/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.5481 - accuracy: 0.8105lr: 0.0001\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.5480 - accuracy: 0.8106 - val_loss: 0.8461 - val_accuracy: 0.7169\n",
      "Epoch 31/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.4546 - accuracy: 0.8414lr: 0.0001\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.4546 - accuracy: 0.8414 - val_loss: 0.7843 - val_accuracy: 0.7456\n",
      "Epoch 32/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.4248 - accuracy: 0.8515lr: 0.0001\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.4250 - accuracy: 0.8515 - val_loss: 0.8099 - val_accuracy: 0.7462\n",
      "Epoch 33/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.4073 - accuracy: 0.8576lr: 0.0001\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.4072 - accuracy: 0.8576 - val_loss: 0.8086 - val_accuracy: 0.7384\n",
      "Epoch 34/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.3944 - accuracy: 0.8628lr: 0.0001\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.3942 - accuracy: 0.8628 - val_loss: 0.7956 - val_accuracy: 0.7437\n",
      "Epoch 35/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.3918 - accuracy: 0.8621lr: 0.0001\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.3918 - accuracy: 0.8621 - val_loss: 0.8358 - val_accuracy: 0.7309\n",
      "Epoch 36/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8663lr: 0.0001\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.3856 - accuracy: 0.8663 - val_loss: 0.8274 - val_accuracy: 0.7344\n",
      "Epoch 37/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.3732 - accuracy: 0.8705lr: 0.0001\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.3731 - accuracy: 0.8705 - val_loss: 0.7907 - val_accuracy: 0.7409\n",
      "Epoch 38/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.3667 - accuracy: 0.8721lr: 0.0001\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.3667 - accuracy: 0.8721 - val_loss: 0.7994 - val_accuracy: 0.7472\n",
      "Epoch 39/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.3628 - accuracy: 0.8736lr: 0.0001\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.3630 - accuracy: 0.8735 - val_loss: 0.8114 - val_accuracy: 0.7437\n",
      "Epoch 40/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.3582 - accuracy: 0.8746lr: 0.0001\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.3583 - accuracy: 0.8746 - val_loss: 0.8259 - val_accuracy: 0.7381\n",
      "Epoch 41/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.3526 - accuracy: 0.8773lr: 0.0001\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.3525 - accuracy: 0.8774 - val_loss: 0.8161 - val_accuracy: 0.7447\n",
      "Epoch 42/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.3481 - accuracy: 0.8798lr: 0.0001\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.3482 - accuracy: 0.8798 - val_loss: 0.8163 - val_accuracy: 0.7472\n",
      "Epoch 43/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.3400 - accuracy: 0.8807lr: 0.0001\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.3401 - accuracy: 0.8807 - val_loss: 0.8304 - val_accuracy: 0.7412\n",
      "Epoch 44/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.3413 - accuracy: 0.8789lr: 0.0001\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.3412 - accuracy: 0.8789 - val_loss: 0.8190 - val_accuracy: 0.7472\n",
      "Epoch 45/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.3366 - accuracy: 0.8811lr: 0.0001\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.3365 - accuracy: 0.8812 - val_loss: 0.8005 - val_accuracy: 0.7556\n",
      "Epoch 46/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.3311 - accuracy: 0.8835lr: 0.0001\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.3310 - accuracy: 0.8835 - val_loss: 0.8499 - val_accuracy: 0.7356\n",
      "Epoch 47/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.3203 - accuracy: 0.8880lr: 0.0001\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.3203 - accuracy: 0.8880 - val_loss: 0.8047 - val_accuracy: 0.7506\n",
      "Epoch 48/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.3162 - accuracy: 0.8895lr: 0.0001\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.3163 - accuracy: 0.8895 - val_loss: 0.8692 - val_accuracy: 0.7331\n",
      "Epoch 49/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.3145 - accuracy: 0.8890lr: 0.0001\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.3144 - accuracy: 0.8891 - val_loss: 0.8673 - val_accuracy: 0.7375\n",
      "Epoch 50/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.3117 - accuracy: 0.8901lr: 0.0001\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.3116 - accuracy: 0.8901 - val_loss: 0.8478 - val_accuracy: 0.7441\n",
      "Epoch 51/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.3089 - accuracy: 0.8903lr: 0.0001\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.3088 - accuracy: 0.8903 - val_loss: 0.8508 - val_accuracy: 0.7462\n",
      "Epoch 52/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.3026 - accuracy: 0.8938lr: 0.0001\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.3026 - accuracy: 0.8938 - val_loss: 0.8539 - val_accuracy: 0.7444\n",
      "Epoch 53/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.3031 - accuracy: 0.8948lr: 0.0001\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.3030 - accuracy: 0.8948 - val_loss: 0.8354 - val_accuracy: 0.7450\n",
      "Epoch 54/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2994 - accuracy: 0.8945lr: 0.0001\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2992 - accuracy: 0.8946 - val_loss: 0.8369 - val_accuracy: 0.7466\n",
      "Epoch 55/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2977 - accuracy: 0.8956lr: 0.0001\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2977 - accuracy: 0.8956 - val_loss: 0.8905 - val_accuracy: 0.7409\n",
      "Epoch 56/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2933 - accuracy: 0.8985lr: 0.0001\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2932 - accuracy: 0.8985 - val_loss: 0.8624 - val_accuracy: 0.7447\n",
      "Epoch 57/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2897 - accuracy: 0.8990lr: 0.0001\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.2896 - accuracy: 0.8991 - val_loss: 0.8803 - val_accuracy: 0.7419\n",
      "Epoch 58/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2788 - accuracy: 0.9020lr: 0.0001\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.2788 - accuracy: 0.9020 - val_loss: 0.8758 - val_accuracy: 0.7475\n",
      "Epoch 59/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2773 - accuracy: 0.9029lr: 0.0001\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2773 - accuracy: 0.9029 - val_loss: 0.8655 - val_accuracy: 0.7456\n",
      "Epoch 60/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2761 - accuracy: 0.9035lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2761 - accuracy: 0.9036 - val_loss: 0.8627 - val_accuracy: 0.7453\n",
      "Epoch 61/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2693 - accuracy: 0.9063lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2692 - accuracy: 0.9063 - val_loss: 0.8601 - val_accuracy: 0.7478\n",
      "Epoch 62/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2643 - accuracy: 0.9074lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2643 - accuracy: 0.9074 - val_loss: 0.8438 - val_accuracy: 0.7494\n",
      "Epoch 63/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2653 - accuracy: 0.9080lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2652 - accuracy: 0.9080 - val_loss: 0.8897 - val_accuracy: 0.7497\n",
      "Epoch 64/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2656 - accuracy: 0.9071lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.2656 - accuracy: 0.9070 - val_loss: 0.8744 - val_accuracy: 0.7372\n",
      "Epoch 65/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2630 - accuracy: 0.9083lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.2631 - accuracy: 0.9083 - val_loss: 0.8542 - val_accuracy: 0.7513\n",
      "Epoch 66/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2634 - accuracy: 0.9090lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2633 - accuracy: 0.9091 - val_loss: 0.8429 - val_accuracy: 0.7500\n",
      "Epoch 67/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2579 - accuracy: 0.9103lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2580 - accuracy: 0.9103 - val_loss: 0.8304 - val_accuracy: 0.7550\n",
      "Epoch 68/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2557 - accuracy: 0.9113lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.2556 - accuracy: 0.9113 - val_loss: 0.8311 - val_accuracy: 0.7462\n",
      "Epoch 69/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2625 - accuracy: 0.9081lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2627 - accuracy: 0.9080 - val_loss: 0.8615 - val_accuracy: 0.7456\n",
      "Epoch 70/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2595 - accuracy: 0.9096lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2594 - accuracy: 0.9096 - val_loss: 0.8495 - val_accuracy: 0.7481\n",
      "Epoch 71/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2623 - accuracy: 0.9077lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2623 - accuracy: 0.9077 - val_loss: 0.8492 - val_accuracy: 0.7456\n",
      "Epoch 72/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2606 - accuracy: 0.9089lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.2606 - accuracy: 0.9089 - val_loss: 0.8938 - val_accuracy: 0.7397\n",
      "Epoch 73/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2580 - accuracy: 0.9100lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2579 - accuracy: 0.9100 - val_loss: 0.8516 - val_accuracy: 0.7475\n",
      "Epoch 74/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2582 - accuracy: 0.9092lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.2581 - accuracy: 0.9093 - val_loss: 0.8409 - val_accuracy: 0.7491\n",
      "Epoch 75/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2609 - accuracy: 0.9098lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.2610 - accuracy: 0.9098 - val_loss: 0.8485 - val_accuracy: 0.7475\n",
      "Epoch 76/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2530 - accuracy: 0.9113lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.2530 - accuracy: 0.9113 - val_loss: 0.8335 - val_accuracy: 0.7516\n",
      "Epoch 77/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2606 - accuracy: 0.9098lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2607 - accuracy: 0.9098 - val_loss: 0.8338 - val_accuracy: 0.7525\n",
      "Epoch 78/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2547 - accuracy: 0.9110lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.2547 - accuracy: 0.9110 - val_loss: 0.8637 - val_accuracy: 0.7478\n",
      "Epoch 79/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2578 - accuracy: 0.9103lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2578 - accuracy: 0.9103 - val_loss: 0.8420 - val_accuracy: 0.7472\n",
      "Epoch 80/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2548 - accuracy: 0.9110lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2549 - accuracy: 0.9110 - val_loss: 0.8457 - val_accuracy: 0.7572\n",
      "Epoch 81/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2556 - accuracy: 0.9110lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2557 - accuracy: 0.9110 - val_loss: 0.8591 - val_accuracy: 0.7459\n",
      "Epoch 82/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2508 - accuracy: 0.9125lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 65s 42ms/step - loss: 0.2507 - accuracy: 0.9126 - val_loss: 0.8502 - val_accuracy: 0.7487\n",
      "Epoch 83/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2541 - accuracy: 0.9110lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2541 - accuracy: 0.9111 - val_loss: 0.8556 - val_accuracy: 0.7503\n",
      "Epoch 84/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2505 - accuracy: 0.9127lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 65s 42ms/step - loss: 0.2506 - accuracy: 0.9126 - val_loss: 0.8400 - val_accuracy: 0.7544\n",
      "Epoch 85/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2597 - accuracy: 0.9095lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.2598 - accuracy: 0.9094 - val_loss: 0.8618 - val_accuracy: 0.7412\n",
      "Epoch 86/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2488 - accuracy: 0.9133lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2487 - accuracy: 0.9134 - val_loss: 0.8698 - val_accuracy: 0.7519\n",
      "Epoch 87/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2503 - accuracy: 0.9140lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.2502 - accuracy: 0.9140 - val_loss: 0.8478 - val_accuracy: 0.7578\n",
      "Epoch 88/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2574 - accuracy: 0.9111lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2573 - accuracy: 0.9111 - val_loss: 0.8654 - val_accuracy: 0.7441\n",
      "Epoch 89/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2503 - accuracy: 0.9133lr: 1.0000000000000003e-05\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2503 - accuracy: 0.9133 - val_loss: 0.8370 - val_accuracy: 0.7494\n",
      "Epoch 90/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2539 - accuracy: 0.9114lr: 1.0000000000000002e-06\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2537 - accuracy: 0.9114 - val_loss: 0.8391 - val_accuracy: 0.7522\n",
      "Epoch 91/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2527 - accuracy: 0.9109lr: 1.0000000000000002e-06\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2528 - accuracy: 0.9109 - val_loss: 0.8417 - val_accuracy: 0.7494\n",
      "Epoch 92/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2467 - accuracy: 0.9147lr: 1.0000000000000002e-06\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2468 - accuracy: 0.9146 - val_loss: 0.8301 - val_accuracy: 0.7553\n",
      "Epoch 93/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2474 - accuracy: 0.9134lr: 1.0000000000000002e-06\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2474 - accuracy: 0.9134 - val_loss: 0.8325 - val_accuracy: 0.7569\n",
      "Epoch 94/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2476 - accuracy: 0.9138lr: 1.0000000000000002e-06\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2475 - accuracy: 0.9138 - val_loss: 0.8454 - val_accuracy: 0.7556\n",
      "Epoch 95/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2518 - accuracy: 0.9113lr: 1.0000000000000002e-06\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2517 - accuracy: 0.9114 - val_loss: 0.8428 - val_accuracy: 0.7475\n",
      "Epoch 96/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2452 - accuracy: 0.9160lr: 1.0000000000000002e-06\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2451 - accuracy: 0.9160 - val_loss: 0.8715 - val_accuracy: 0.7409\n",
      "Epoch 97/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2524 - accuracy: 0.9118lr: 1.0000000000000002e-06\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2526 - accuracy: 0.9118 - val_loss: 0.9009 - val_accuracy: 0.7400\n",
      "Epoch 98/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2533 - accuracy: 0.9121lr: 1.0000000000000002e-06\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2532 - accuracy: 0.9121 - val_loss: 0.8511 - val_accuracy: 0.7519\n",
      "Epoch 99/100\n",
      "1560/1562 [============================>.] - ETA: 0s - loss: 0.2479 - accuracy: 0.9145lr: 1.0000000000000002e-06\n",
      "1562/1562 [==============================] - 65s 41ms/step - loss: 0.2478 - accuracy: 0.9146 - val_loss: 0.8481 - val_accuracy: 0.7450\n",
      "Epoch 100/100\n",
      "1561/1562 [============================>.] - ETA: 0s - loss: 0.2504 - accuracy: 0.9126lr: 1.0000000000000002e-06\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.2504 - accuracy: 0.9126 - val_loss: 0.8532 - val_accuracy: 0.7572\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "dataset = 'cifar10'\n",
    "train_size = 50000\n",
    "image_size = 32\n",
    "batch_size = 32\n",
    "reduction_ratio = 16\n",
    "num_classes = 10\n",
    "momentum = 0.8\n",
    "initial_learning_rate = 0.001\n",
    "drop_rate = 0.1\n",
    "epochs_per_drop = 30.0\n",
    "steps_per_epoch = train_size // batch_size\n",
    "epochs = 100\n",
    "\n",
    "ds_train = tfds.load(dataset, split='train')\n",
    "ds_test = tfds.load(dataset, split='test')\n",
    "\n",
    "def normalize_image(ele):\n",
    "    image = ele['image']\n",
    "    label = ele['label']\n",
    "    paddings = tf.constant([[4,4], [4,4], [0,0]])\n",
    "  \n",
    "    image = tf.pad(image, paddings, 'CONSTANT')\n",
    "    image = tf.image.random_crop(image, size = [32,32,3])\n",
    "    \n",
    "    image = (image - tf.reduce_min(image))/(tf.reduce_max(image)-tf.reduce_min(image))\n",
    "    return image, label\n",
    "\n",
    "ds_train = ds_train.map(normalize_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).repeat().shuffle(100).batch(batch_size).prefetch(1)\n",
    "ds_test = ds_test.map(normalize_image,  num_parallel_calls=tf.data.experimental.AUTOTUNE).repeat().shuffle(100).batch(batch_size).prefetch(1)\n",
    "\n",
    "def conv2D(x, filters, kernel=(3,3), strides=(1,1), activation=tf.nn.relu, use_bias=False):\n",
    "    x = tf.keras.layers.Conv2D(filters, kernel_size=kernel, strides=strides, use_bias=use_bias, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    if activation is not None:\n",
    "        x = tf.keras.layers.Activation(activation)(x)\n",
    "    return x\n",
    "\n",
    "def SE_layer(x, ratio=reduction_ratio):\n",
    "    depth = list(x.get_shape())[-1]\n",
    "    prev = x\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(depth//ratio, activation=tf.nn.relu)(x)\n",
    "    x = tf.keras.layers.Dense(depth, activation=tf.nn.sigmoid)(x)\n",
    "    x = tf.reshape(x, [-1, 1, 1, depth])\n",
    "    x = prev * x\n",
    "    return x\n",
    "\n",
    "def block(x, trips=[64, 64, 256], first=False, SE=False):\n",
    "    if first:\n",
    "        x = conv2D(x, trips[0], kernel=(1,1), strides=(2,2))\n",
    "    else:\n",
    "        x = conv2D(x, trips[0], kernel=(1,1))\n",
    "    x = conv2D(x, trips[1], kernel=(3,3))\n",
    "    x = conv2D(x, trips[2], kernel=(1,1))\n",
    "    if SE:\n",
    "        x = SE_layer(x)\n",
    "    return x\n",
    "\n",
    "def meta_block(x, trips=[64, 64, 256], repeats=3, downsample=True, SE=False):\n",
    "    prev = x\n",
    "    for r in range(repeats):\n",
    "        if r == 0 and downsample:\n",
    "            prev = conv2D(prev, trips[2], kernel=(1,1), strides=(2,2), activation=None)\n",
    "            x = block(x, trips=trips, first=True, SE=SE)\n",
    "            x = tf.keras.layers.Add()([x, prev])\n",
    "        elif r==0 and not downsample:\n",
    "            prev = conv2D(prev, trips[2], kernel=(1,1), activation=None)\n",
    "            x = block(x, trips=trips, SE=SE)\n",
    "            x = tf.keras.layers.Add()([x, prev])\n",
    "        else:\n",
    "            prev = x\n",
    "            x = block(x, trips=trips, SE=SE)\n",
    "            x = tf.keras.layers.Add()([x, prev])\n",
    "    return x\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(image_size, image_size, 3))\n",
    "x = conv2D(inputs, 64, kernel=(7,7), strides=(2,2))\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=2, padding='same')(x)                         \n",
    "\n",
    "### Block 1\n",
    "x = meta_block(x, trips=[64, 64, 256], repeats=3, downsample=False, SE=False)\n",
    "\n",
    "### Block 2\n",
    "x = meta_block(x, trips=[128, 128, 512], repeats=4, SE=False)\n",
    "\n",
    "### Block 3\n",
    "x = meta_block(x, trips=[256, 256, 1024], repeats=6, SE=False)\n",
    "\n",
    "### Block 4\n",
    "x = meta_block(x, trips=[512, 512, 2048], repeats=3)\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(num_classes, activation='softmax')(x) #logits \n",
    "\n",
    "SE_resnet = tf.keras.Model(inputs, x)\n",
    "\n",
    "sgd = tf.keras.optimizers.SGD(lr=0.0, momentum=momentum, decay=0.0, nesterov=False) \n",
    "\n",
    "SE_resnet.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "class LossHistory(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.lr = []\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.lr.append(step_decay(len(self.losses)))\n",
    "        print('lr:', step_decay(len(self.losses)))\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = initial_learning_rate\n",
    "    drop = drop_rate\n",
    "    epochs_drop = epochs_per_drop\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "# learning schedule callback\n",
    "loss_history = LossHistory()\n",
    "lrate = tf.keras.callbacks.LearningRateScheduler(step_decay)\n",
    "callbacks_list = [loss_history, lrate]\n",
    "\n",
    "# fit the model\n",
    "history = SE_resnet.fit(ds_train, steps_per_epoch=steps_per_epoch, validation_data=ds_test, epochs=epochs, callbacks=callbacks_list, validation_steps=100)\n",
    "\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "np.savetxt(\"resnet_cifar10_accuracy.csv\", accuracy, delimiter=\",\")\n",
    "np.savetxt(\"resnet_cifar10_val_accuracy.csv\", val_accuracy, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
